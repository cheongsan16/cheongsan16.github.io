---
layout: default
title: 21-2 AI학습용데이터활용 프로젝트
parent: AI
nav_order: 2
---

# 21-2 AI학습용데이터활용 프로젝트

목표 : 세 종류의 와인을 분류하라<br>
데이터 : https://archive.ics.uci.edu/ml/datasets/Wine

세 가지 클래스로 분류하기 위해 두 가지 모델을 사용함.
1. Decision Tree 활용 다중분류
2. Logisitic 회귀 활용 이진분류
3. Softmax 활용 다중분류

### Decision Tree 활용 다중분류

13가지 피처를 모두 학습한 경우 -> 정확도 0.9630<br>
하이퍼 파라미터 튜닝 후(max_depth, min_samples_split) -> 정확도 0.9815<br>
피처중요도 시각화, 중요도 상위 5개 피처로 학습한 경우 -> 정확도 0.9815

### Logisitic 회귀 활용 이진분류

(1학년 때 했던 프로젝트라.. 다중분류기 모를 때...)<br>
for문 활용, 클래스를 하나씩 드롭하여 이진분류를 3번 진행함.<br>


목표는 세 가지의 와인 종류를 분류하는 것 입니다.
데이터에 대한 이야기를 하겠습니다. 첫번째 열에 레이블 값이 있어서, 따로 분리를 했고요. 피처는 알콜 도수부터 13가지가 있는데요, 와인에 함유된 여러 성분들로 구성되어 있습니다.

3개 클래스의, 세 종류의 와인을 분류하는 문제이기 때문에, 분류 알고리즘을 사용했습니다. 클래스가 3개인, 다중 분류 문제라 Decision Tree를 사용했습니다. 근데 이것만 하기가 조금 아쉬워서, 로지스틱 회귀는 다중 분류 문제에서 사용하려면 추가적인 기능이 필요한데, 수업 내용 이상의 추가적인 개념이 필요해서 for문 돌려서 클래스를 하나씩 드롭해서 각각 총 세 번 회귀를 돌리는 방향으로 실행해봤습니다.

(코드를 보여주거나 아니거나)
위에는 학습을 진행하기 위해 레이블 열과 분리하고 난 이후 정리된 모습입니다.
이제 이 데이터로 학습을 진행하는데요, 코드에 대한 자세한 설명을 생략하도록 하겠습니다.
그냥 원본 데이터로 학습했을 때는 정확도가 0.9630이 나왔는데, 하이퍼 파라미터 max_depth와 min_samples_split를 튜닝한 이후에는 0.9815로 향상되었습니다.
그리고 피처중요도를 시각화해봤는데, 이렇게 나왔습니다. 어떤 게 제일 크고, 피처 네 가지가 거의 결정하고 있네요.
다음은 로지스틱 회귀의 내용입니다. 크게 두 가지 구조로 코드르 짰습니다. for문 안에서 이 함수를 사용하는 형태인데, 함수를 통해 정규분포 형태로 스케일링하고 train, test 데이터를 분리하여 학습, 예측을 하고 그 데이터를 반환하면 이를 이용하여 for문에서 평가를 수행합니다.
이를 통해 총 3번의 회귀를 진행하였고, 이러한 평가 결과를 받았습니다. 전체적으로 상당히 높은 결과를 보이는데 레이블 2, 3번으로 회귀를 수행한 것이 약간의 오차가 있지만 다른 것들은 완벽하게 분류해내는 것을 알 수 있습니다.
